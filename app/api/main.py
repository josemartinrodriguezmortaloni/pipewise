## main.py - ConfiguraciÃ³n principal de FastAPI con autenticaciÃ³n
import os
import logging
from contextlib import asynccontextmanager
from fastapi import (
    FastAPI,
    Request,
    HTTPException,
    status,
    APIRouter,
    Depends,
    BackgroundTasks,
)
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
import uvicorn
from dotenv import load_dotenv
from typing import Dict, Any
import uuid

# Importaciones del sistema de autenticaciÃ³n
from app.api.auth import router as auth_router
from app.auth.supabase_auth_client import (
    get_supabase_auth_client,
    cleanup_supabase_auth_keys,
    SupabaseAuthClient,
)
from app.auth.utils import get_client_ip

# Importaciones de routers (movidas al principio)
from app.api.api import router as crm_router
from app.api.webhooks import router as webhooks_router
from app.api.search import router as search_router
from app.api.config import router as config_router
from app.api.integrations import router as integrations_router
from app.api.agent_config import router as agent_config_router
from app.api.calendar import router as calendar_router

# Importaciones existentes del CRM
# from app.api.api import app as crm_app  # Comentado para tests
from app.agents.agents import ModernAgents as Agents
from app.schemas.auth_schema import UserProfile as User
from app.agents.agents import ModernAgents, TenantContext
from app.supabase.supabase_client import SupabaseCRMClient

# Cargar variables de entorno
load_dotenv()

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("app.log"), logging.StreamHandler()],
)
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """GestiÃ³n del ciclo de vida de la aplicaciÃ³n"""
    # Startup
    logger.info("ðŸš€ Starting PipeWise CRM with Authentication...")

    # Verificar servicios crÃ­ticos
    await startup_checks()

    # Inicializar tareas de limpieza
    await schedule_cleanup_tasks()

    logger.info("âœ… Application started successfully")

    yield

    # Shutdown
    logger.info("ðŸ›‘ Shutting down application...")
    await cleanup_resources()
    logger.info("âœ… Application shutdown complete")


async def startup_checks():
    """Verificaciones de inicio"""
    try:
        # Verificar Supabase Auth
        supabase_auth_client = await get_supabase_auth_client()
        supabase_health = await supabase_auth_client.health_check()
        logger.info(f"Supabase Auth Status: {supabase_health['status']}")

        # Email functionality now handled by SendGrid MCP integration
        logger.info("Email Service: Using SendGrid MCP integration")

        # Verificar CRM Agents
        try:
            _ = Agents()  # Usar _ para indicar que no necesitamos la variable
            logger.info("âœ… CRM Agents initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ CRM Agents initialization warning: {e}")

    except Exception as e:
        logger.error(f"âŒ Startup check failed: {e}")


async def schedule_cleanup_tasks():
    """Programar tareas de limpieza"""
    try:
        # Limpiar claves expiradas de Supabase
        cleaned = await cleanup_supabase_auth_keys()
        logger.info(f"Cleaned {cleaned} expired Supabase auth keys")
    except Exception as e:
        logger.error(f"Cleanup task failed: {e}")


async def cleanup_resources():
    """Limpiar recursos al cerrar"""
    try:
        supabase_auth_client = await get_supabase_auth_client()
        await supabase_auth_client.close()
    except Exception as e:
        logger.error(f"Error closing resources: {e}")


# Crear aplicaciÃ³n FastAPI
app = FastAPI(
    title="PipeWise CRM with Authentication",
    description="Complete CRM system with advanced authentication and 2FA",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan,
)

# ===================== CONFIGURACIÃ“N DE CORS =====================

# Configurar CORS
allowed_origins = [
    "http://localhost:3000",  # React development
    "http://localhost:3001",  # Alternative React port
    "http://127.0.0.1:3000",
    "https://app.pipewise.com",  # Production frontend
    "https://pipewise.vercel.app",  # Vercel deployment
]

# Agregar origins adicionales desde variables de entorno
additional_origins = os.getenv("ALLOWED_ORIGINS", "").split(",")
allowed_origins.extend(
    [origin.strip() for origin in additional_origins if origin.strip()]
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=allowed_origins,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE", "OPTIONS", "PATCH"],
    allow_headers=["*"],
    expose_headers=["X-Total-Count", "X-Rate-Limit-Remaining", "X-Rate-Limit-Reset"],
)

# ===================== MIDDLEWARE DE SEGURIDAD =====================

# Hosts confiables
trusted_hosts = ["localhost", "127.0.0.1", "*.pipewise.com", "testserver"]
additional_hosts = os.getenv("TRUSTED_HOSTS", "").split(",")
trusted_hosts.extend([host.strip() for host in additional_hosts if host.strip()])

app.add_middleware(TrustedHostMiddleware, allowed_hosts=trusted_hosts)


# ===================== MIDDLEWARE PERSONALIZADO =====================


@app.middleware("http")
async def security_headers_middleware(request: Request, call_next):
    """Agregar headers de seguridad"""
    response = await call_next(request)

    # Headers de seguridad
    response.headers["X-Content-Type-Options"] = "nosniff"
    response.headers["X-Frame-Options"] = "DENY"
    response.headers["X-XSS-Protection"] = "1; mode=block"
    response.headers["Referrer-Policy"] = "strict-origin-when-cross-origin"

    # CSP bÃ¡sico
    response.headers["Content-Security-Policy"] = (
        "default-src 'self'; "
        "script-src 'self' 'unsafe-inline'; "
        "style-src 'self' 'unsafe-inline'; "
        "img-src 'self' data: https:; "
        "connect-src 'self'"
    )

    return response


# @app.middleware("http")
# async def logging_middleware(request: Request, call_next):
#     """Middleware de logging para requests"""
#     import time

#     start_time = time.time()
#     client_ip = get_client_ip(request)
#     user_agent = get_user_agent(request)

#     # Log del request
#     logger.info(f"Request: {request.method} {request.url.path} from {client_ip}")

#     try:
#         response = await call_next(request)

#         # Calcular tiempo de procesamiento
#         process_time = time.time() - start_time
#         response.headers["X-Process-Time"] = str(process_time)

#         # Log de la respuesta
#         logger.info(
#             f"Response: {response.status_code} for {request.method} {request.url.path} in {process_time:.4f}s"
#         )

#         return response

#     except Exception as e:
#         process_time = time.time() - start_time
#         logger.error(
#             f"Request failed: {request.method} {request.url.path} after {process_time:.4f}s - {str(e)}"
#         )
#         raise


# @app.middleware("http")
# async def rate_limiting_middleware(request: Request, call_next):
#     """Middleware bÃ¡sico de rate limiting"""
#     try:
#         # Aplicar rate limiting solo a ciertas rutas
#         sensitive_paths = ["/auth/login", "/auth/register", "/auth/forgot-password"]

#         if any(request.url.path.startswith(path) for path in sensitive_paths):
#             client_ip = get_client_ip(request)

#             # Verificar rate limit
#             rate_check = await redis_auth_client.check_rate_limit(
#                 identifier=f"ip:{client_ip}",
#                 limit=10,  # 10 requests por hora
#                 window=3600,
#             )

#             if not rate_check["allowed"]:
#                 logger.warning(f"Rate limit exceeded for {client_ip}")
#                 return JSONResponse(
#                     status_code=status.HTTP_429_TOO_MANY_REQUESTS,
#                     content={
#                         "error": "Too many requests",
#                         "detail": "Rate limit exceeded. Please try again later.",
#                         "retry_after": rate_check.get("reset_time", 3600),
#                     },
#                     headers={
#                         "X-Rate-Limit-Limit": str(rate_check["limit"]),
#                         "X-Rate-Limit-Remaining": str(
#                             max(0, rate_check["limit"] - rate_check["count"])
#                         ),
#                         "X-Rate-Limit-Reset": str(rate_check.get("reset_time", 0)),
#                         "Retry-After": str(3600),
#                     },
#                 )

#         return await call_next(request)

#     except Exception as e:
#         logger.error(f"Rate limiting middleware error: {e}")
#         return await call_next(request)


# ===================== MANEJADORES DE ERRORES =====================


@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Manejador personalizado de excepciones HTTP"""
    from datetime import datetime

    client_ip = get_client_ip(request)
    logger.warning(
        f"HTTP {exc.status_code}: {exc.detail} for {request.method} {request.url.path} from {client_ip}"
    )

    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "timestamp": datetime.utcnow().isoformat(),
            "path": request.url.path,
        },
    )


@app.exception_handler(ValueError)
async def value_error_handler(request: Request, exc: ValueError):
    """Manejador de errores de validaciÃ³n"""
    from datetime import datetime

    logger.error(f"ValueError: {str(exc)} for {request.method} {request.url.path}")

    return JSONResponse(
        status_code=status.HTTP_400_BAD_REQUEST,
        content={
            "error": "Validation error",
            "detail": str(exc),
            "status_code": 400,
            "timestamp": datetime.utcnow().isoformat(),
        },
    )


@app.exception_handler(Exception)
async def general_exception_handler(request: Request, exc: Exception):
    """Manejador general de excepciones"""
    from datetime import datetime

    client_ip = get_client_ip(request)
    logger.error(
        f"Unhandled exception: {str(exc)} for {request.method} {request.url.path} from {client_ip}",
        exc_info=True,
    )

    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content={
            "error": "Internal server error",
            "detail": "An unexpected error occurred",
            "status_code": 500,
            "timestamp": datetime.utcnow().isoformat(),
        },
    )


# ===================== RUTAS PRINCIPALES =====================

# Incluir router de autenticaciÃ³n
app.include_router(auth_router)

# Incluir router de CRM
app.include_router(crm_router)

# Incluir router de webhooks y notificaciones
app.include_router(webhooks_router)

# Incluir router de bÃºsqueda y exportaciÃ³n
app.include_router(search_router)

# Incluir router de configuraciÃ³n
app.include_router(config_router)

# Incluir router de integraciones
app.include_router(integrations_router)

# Incluir router de configuraciÃ³n de agentes
app.include_router(agent_config_router)

# Incluir router de calendario
app.include_router(calendar_router)

# TODO: Add user configuration router after fixing authentication dependencies


# ===================== RUTAS DE SALUD Y ESTADO =====================


@app.get("/")
async def root():
    """Endpoint raÃ­z"""
    return {
        "message": "PipeWise CRM API with Authentication",
        "version": "2.0.0",
        "status": "running",
        "features": [
            "Advanced Authentication",
            "Two-Factor Authentication",
            "CRM Lead Management",
            "AI Agents Integration",
            "Rate Limiting",
            "Email Notifications",
        ],
    }


@app.get("/health")
async def health_check():
    """Health check simplificado del sistema"""
    from datetime import datetime

    # Simplified health check that always returns healthy during testing
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "2.0.0",
    }


@app.get("/metrics")
async def get_metrics():
    """Obtener mÃ©tricas del sistema en formato Prometheus"""
    from datetime import datetime
    from starlette.responses import PlainTextResponse

    try:
        # Formato bÃ¡sico de mÃ©tricas Prometheus
        metrics_text = f"""# HELP pipewise_app_info Information about PipeWise application
# TYPE pipewise_app_info gauge
pipewise_app_info{{version="2.0.0"}} 1

# HELP pipewise_uptime_seconds Time since application startup
# TYPE pipewise_uptime_seconds gauge
pipewise_uptime_seconds 100

# HELP pipewise_health_status Health status of the application (1=healthy, 0=unhealthy)
# TYPE pipewise_health_status gauge
pipewise_health_status 1

# HELP pipewise_timestamp_seconds Current timestamp
# TYPE pipewise_timestamp_seconds gauge
pipewise_timestamp_seconds {datetime.utcnow().timestamp()}
"""

        return PlainTextResponse(content=metrics_text, media_type="text/plain")

    except Exception as e:
        logger.error(f"Metrics error: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to retrieve metrics",
        )


# ===================== CONFIGURACIÃ“N DE DESARROLLO =====================

if __name__ == "__main__":
    # ConfiguraciÃ³n para desarrollo
    host = os.getenv("HOST", "0.0.0.0")
    port = int(os.getenv("PORT", "8000"))
    debug = os.getenv("DEBUG", "True").lower() == "true"

    logger.info(f"Starting server on {host}:{port} (debug={debug})")

    uvicorn.run(
        "main:app",
        host=host,
        port=port,
        reload=debug,
        access_log=True,
        log_level="info" if not debug else "debug",
    )


# ===================== CONFIGURACIÃ“N DE PRODUCCIÃ“N =====================

# Para producciÃ³n, usar:
# gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker -b 0.0.0.0:8000

# O con uvicorn:
# uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4


# ===================== TAREAS PROGRAMADAS (OPCIONAL) =====================


# Para usar con APScheduler o similar
async def scheduled_cleanup():
    """Tarea programada de limpieza"""
    try:
        # Limpiar Supabase Auth
        cleaned_supabase = await cleanup_supabase_auth_keys()
        logger.info(f"Scheduled cleanup: {cleaned_supabase} Supabase auth keys cleaned")

        # Limpiar base de datos (tokens expirados)
        # Implementar segÃºn necesidades

    except Exception as e:
        logger.error(f"Scheduled cleanup error: {e}")


# ConfiguraciÃ³n de tareas programadas (comentado por defecto)
"""
from apscheduler.schedulers.asyncio import AsyncIOScheduler
import atexit

scheduler = AsyncIOScheduler()
scheduler.add_job(
    func=scheduled_cleanup,
    trigger="interval",
    minutes=30,  # Cada 30 minutos
    id='cleanup_job'
)

# Iniciar scheduler
scheduler.start()

# Asegurar que se cierre al terminar la aplicaciÃ³n
atexit.register(lambda: scheduler.shutdown())
"""

# ============================================================================
# USER ACCOUNT CONFIGURATION ENDPOINTS
# ============================================================================

router = APIRouter()

# Authentication dependency
auth_client = SupabaseAuthClient()


async def get_current_user_id() -> str:
    """Get current authenticated user ID from Supabase"""
    # This is a placeholder implementation - should be replaced with actual Supabase JWT validation
    # For now, return a mock user ID to avoid breaking the API
    return "mock_user_id"


async def get_current_user(
    user_id: str = Depends(get_current_user_id),
) -> User:
    """Get current authenticated user"""
    if not user_id:
        raise HTTPException(status_code=401, detail="Authentication required")

    # Get user from Supabase
    supabase_client = SupabaseCRMClient()
    user_data = (
        supabase_client.client.table("users").select("*").eq("id", user_id).execute()
    )

    if not user_data.data:
        raise HTTPException(status_code=404, detail="User not found")

    # Map Supabase user data to UserProfile schema
    user_record = user_data.data[0]
    return User(
        user_id=user_record.get("id", user_id),
        email=user_record.get("email", ""),
        full_name=user_record.get("full_name", ""),
        company=user_record.get("company"),
        phone=user_record.get("phone"),
        role=user_record.get("role", "user"),
        is_active=user_record.get("is_active", True),
        email_confirmed=user_record.get("email_confirmed", False),
        has_2fa=user_record.get("has_2fa", False),
        created_at=user_record.get("created_at", "2024-01-01T00:00:00Z"),
        last_login=user_record.get("last_login"),
    )


@router.get("/user/integrations/accounts")
async def get_user_accounts(user: User = Depends(get_current_user)):
    """Get user's configured accounts"""
    try:
        supabase_client = SupabaseCRMClient()

        accounts_data = (
            supabase_client.client.table("user_accounts")
            .select("account_id, account_type, configuration, connected, created_at")
            .eq("user_id", user.user_id)
            .execute()
        )

        return {"accounts": accounts_data.data, "total": len(accounts_data.data)}
    except Exception as e:
        logger.error(f"Error fetching user accounts: {e}")
        raise HTTPException(status_code=500, detail="Error fetching accounts")


@router.post("/user/integrations/accounts")
async def save_user_account(
    account_data: Dict[str, Any], user: User = Depends(get_current_user)
):
    """Save or update user account configuration"""
    try:
        supabase_client = SupabaseCRMClient()

        # Validate required fields
        required_fields = ["account_id", "account_type", "configuration"]
        for field in required_fields:
            if field not in account_data:
                raise HTTPException(
                    status_code=400, detail=f"Missing required field: {field}"
                )

        # Check if account already exists
        existing = (
            supabase_client.client.table("user_accounts")
            .select("*")
            .eq("user_id", user.user_id)
            .eq("account_id", account_data["account_id"])
            .execute()
        )

        account_record = {
            "user_id": user.user_id,
            "account_id": account_data["account_id"],
            "account_type": account_data["account_type"],
            "configuration": account_data["configuration"],
            "connected": True,
            "updated_at": "now()",
        }

        if existing.data:
            # Update existing account
            result = (
                supabase_client.client.table("user_accounts")
                .update(account_record)
                .eq("user_id", user.user_id)
                .eq("account_id", account_data["account_id"])
                .execute()
            )
        else:
            # Create new account
            account_record["created_at"] = "now()"
            result = (
                supabase_client.client.table("user_accounts")
                .insert(account_record)
                .execute()
            )

        return {
            "success": True,
            "message": f"Account {account_data['account_id']} configured successfully",
            "account": result.data[0] if result.data else None,
        }

    except Exception as e:
        logger.error(f"Error saving user account: {e}")
        raise HTTPException(status_code=500, detail=f"Error saving account: {str(e)}")


@router.delete("/user/integrations/accounts/{account_id}")
async def disconnect_user_account(
    account_id: str, user: User = Depends(get_current_user)
):
    """Disconnect user account"""
    try:
        supabase_client = SupabaseCRMClient()

        # Update account to disconnected
        result = (
            supabase_client.client.table("user_accounts")
            .update({"connected": False, "updated_at": "now()"})
            .eq("user_id", user.user_id)
            .eq("account_id", account_id)
            .execute()
        )

        if not result.data:
            raise HTTPException(status_code=404, detail="Account not found")

        return {
            "success": True,
            "message": f"Account {account_id} disconnected successfully",
        }

    except Exception as e:
        logger.error(f"Error disconnecting account: {e}")
        raise HTTPException(status_code=500, detail="Error disconnecting account")


# ============================================================================
# COMMUNICATION TARGETS ENDPOINTS
# ============================================================================


@router.get("/user/communication-targets")
async def get_communication_targets(user: User = Depends(get_current_user)):
    """Get user's communication targets"""
    try:
        supabase_client = SupabaseCRMClient()

        targets_data = (
            supabase_client.client.table("communication_targets")
            .select(
                "id, name, email, twitter_username, instagram_username, notes, active, created_at"
            )
            .eq("user_id", user.user_id)
            .eq("active", True)
            .execute()
        )

        return {"targets": targets_data.data, "total": len(targets_data.data)}
    except Exception as e:
        logger.error(f"Error fetching communication targets: {e}")
        raise HTTPException(status_code=500, detail="Error fetching targets")


@router.post("/user/communication-targets")
async def add_communication_target(
    target_data: Dict[str, Any], user: User = Depends(get_current_user)
):
    """Add new communication target"""
    try:
        supabase_client = SupabaseCRMClient()

        # Validate required fields
        if not target_data.get("name"):
            raise HTTPException(status_code=400, detail="Name is required")

        # Validate at least one communication method
        if not any(
            [
                target_data.get("email"),
                target_data.get("twitter_username"),
                target_data.get("instagram_username"),
            ]
        ):
            raise HTTPException(
                status_code=400,
                detail="At least one communication method (email, twitter, instagram) is required",
            )

        target_record = {
            "id": str(uuid.uuid4()),
            "user_id": user.user_id,
            "name": target_data["name"],
            "email": target_data.get("email"),
            "twitter_username": target_data.get("twitter_username"),
            "instagram_username": target_data.get("instagram_username"),
            "notes": target_data.get("notes"),
            "active": True,
            "created_at": "now()",
        }

        result = (
            supabase_client.client.table("communication_targets")
            .insert(target_record)
            .execute()
        )

        return result.data[0] if result.data else target_record

    except Exception as e:
        logger.error(f"Error adding communication target: {e}")
        raise HTTPException(status_code=500, detail=f"Error adding target: {str(e)}")


@router.delete("/user/communication-targets/{target_id}")
async def remove_communication_target(
    target_id: str, user: User = Depends(get_current_user)
):
    """Remove communication target"""
    try:
        supabase_client = SupabaseCRMClient()

        # Soft delete by setting active to false
        result = (
            supabase_client.client.table("communication_targets")
            .update({"active": False, "updated_at": "now()"})
            .eq("user_id", user.user_id)
            .eq("id", target_id)
            .execute()
        )

        if not result.data:
            raise HTTPException(status_code=404, detail="Target not found")

        return {"success": True, "message": "Communication target removed successfully"}

    except Exception as e:
        logger.error(f"Error removing communication target: {e}")
        raise HTTPException(status_code=500, detail="Error removing target")


# ============================================================================
# ORCHESTRATOR WORKFLOW ENDPOINTS
# ============================================================================


@router.post("/orchestrator/initiate-communications")
async def initiate_communications(
    user: User = Depends(get_current_user),
    background_tasks: BackgroundTasks = BackgroundTasks(),
):
    """Initiate communications with all configured targets"""
    try:
        supabase_client = SupabaseCRMClient()

        # Get user's communication targets
        targets_data = (
            supabase_client.client.table("communication_targets")
            .select("*")
            .eq("user_id", user.user_id)
            .eq("active", True)
            .execute()
        )

        if not targets_data.data:
            return {"success": False, "message": "No communication targets configured"}

        # Get user's account configurations
        accounts_data = (
            supabase_client.client.table("user_accounts")
            .select("*")
            .eq("user_id", user.user_id)
            .eq("connected", True)
            .execute()
        )

        user_accounts = {
            acc["account_id"]: acc["configuration"] for acc in accounts_data.data
        }

        # Initialize orchestrator workflow
        tenant_context = TenantContext(
            tenant_id=user.user_id,
            user_id=user.user_id,
            is_premium=getattr(user, "is_premium", False),
            api_limits={},
            features_enabled=["twitter", "email", "instagram"],
            memory_manager=None,
        )

        modern_agents = ModernAgents(tenant_context)

        # Schedule background task for each target
        communication_tasks = []
        for target in targets_data.data:
            task_data = {
                "target": target,
                "user_accounts": user_accounts,
                "user_id": user.user_id,
            }
            background_tasks.add_task(
                process_target_communication, task_data, modern_agents
            )
            communication_tasks.append(
                {
                    "target_name": target["name"],
                    "methods": [
                        method
                        for method in [
                            "email",
                            "twitter_username",
                            "instagram_username",
                        ]
                        if target.get(method)
                    ],
                }
            )

        return {
            "success": True,
            "message": f"Communication initiated with {len(targets_data.data)} targets",
            "tasks": communication_tasks,
        }

    except Exception as e:
        logger.error(f"Error initiating communications: {e}")
        raise HTTPException(
            status_code=500, detail=f"Error initiating communications: {str(e)}"
        )


async def process_target_communication(
    task_data: Dict[str, Any], modern_agents: ModernAgents
):
    """Background task to process communication with a single target"""
    try:
        target = task_data["target"]
        user_accounts = task_data["user_accounts"]

        logger.info(f"Processing communication with target: {target['name']}")

        # Prepare communication data based on available methods
        communication_methods = []

        if target.get("email") and "google_account" in user_accounts:
            communication_methods.append(
                {
                    "type": "email",
                    "target": target["email"],
                    "config": user_accounts["google_account"],
                }
            )

        if target.get("twitter_username") and "twitter_account" in user_accounts:
            communication_methods.append(
                {
                    "type": "twitter",
                    "target": target["twitter_username"],
                    "config": user_accounts["twitter_account"],
                }
            )

        if target.get("instagram_username") and "instagram_account" in user_accounts:
            communication_methods.append(
                {
                    "type": "instagram",
                    "target": target["instagram_username"],
                    "config": user_accounts["instagram_account"],
                }
            )

        # Process each communication method
        for method in communication_methods:
            try:
                # This would trigger the orchestrator to initiate communication
                # For now, we log the intended action
                logger.info(
                    f"Would initiate {method['type']} communication with {target['name']}"
                )

            except Exception as method_error:
                logger.error(
                    f"Error with {method['type']} communication for {target['name']}: {method_error}"
                )
                continue

        logger.info(f"Completed communication processing for target: {target['name']}")

    except Exception as e:
        logger.error(f"Error in background communication task: {e}")
